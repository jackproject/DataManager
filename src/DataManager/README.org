

* nextstep

** DONE 新需求
   - State "DONE"       from ""           [2016-05-12 周四 20:19]
   CLOCK: [2016-05-12 周四 19:54]--[2016-05-12 周四 20:19] =>  0:25
   CLOCK: [2016-05-12 周四 19:04]--[2016-05-12 周四 19:35] =>  0:31

1. 100条 水平条  -> 20 条

2. 统一 "删除按钮" 的按钮样式

3. 创建筛选条件， 增加字段的提示
   请输入格式
   数字
   字符串
   序列值


---------
有余力的，剩余的

1. 匹配多个字段， 或者的关系

2. 界面边框

3. 字符的
   对于

4. 显示

5. “选择文件" 是否带图片 （延迟）

6. 上传文件时，提示“正在处理中”对话框，等上传完成之后 取消对话框（延迟）


** 界面调整
   CLOCK: [2016-05-11 周三 21:42]--[2016-05-11 周三 22:42] =>  1:00

右侧的表格好像偏移到浏览器外了

表格右侧没有和上方的灰色对齐

** 部署
   CLOCK: [2016-05-12 周四 20:19]
   CLOCK: [2016-05-10 周二 22:03]--[2016-05-10 周二 22:47] =>  0:44

演示地址： http://119.29.102.203:22080/DataManager/

【注意事项】

1. 上传 excel 时，在数据量比较大时，需要一定的时间解析，请在上传之后，等待“上传成功”的提示。

2. 本地保存日志，采用的txt的形式。因为在 linux 服务器中，创建excel比较麻烦，而且 txt 已经可以保存日志信息了。所以暂时采用的txt
   如果浏览器打开乱码，可以先保存到电脑上打开即可
** 日期筛选
   CLOCK: [2016-05-11 周三 19:27]--[2016-05-11 周三 19:36] =>  0:09


格式化是这种格式：


关于日期筛选出错：

本地测试，yyyy-MM-dd 这种格式的记录日期筛选是没问题的。

查看 网站 上的记录：
猜测上传的 excel 中估计输入是：2015.12.04，由于服务器解析的日期字符串是按 “yyyy-MM-dd” 这种格式进行解析的，中间是 - 分割。从而格式错误，造成日期解析出错。引起的日期筛选出错。




** 日志编码
   CLOCK: [2016-05-11 周三 20:33]--[2016-05-11 周三 20:49] =>  0:16

java.io.UnsupportedEncodingException:  UTF-8 


改成 GBK 编码


			FileOutputStream fos = new FileOutputStream(path);
			OutputStreamWriter osw = new OutputStreamWriter(fos, "gbk");
	        



** DONE 表格缩进
   - State "DONE"       from ""           [2016-05-11 周三 20:32]
   CLOCK: [2016-05-11 周三 20:17]--[2016-05-11 周三 20:27] =>  0:10
   CLOCK: [2016-05-11 周三 19:38]--[2016-05-11 周三 19:46] =>  0:08



表格列头因为不知道具体字段该字段内容的长度，暂时有两种处理方案
1. 统一设定每列的最小宽度 200px
2. 根据表头内容长度进行相应的设置，字段头越长，内容越宽。
   这样也存在问题，比如“备注”不长，但内容会比较多，内容的显示也不是很好看。

两种方式都可以实现，不知哪种你们容易接受些。

http://119.29.102.203:22080/DataManager/#/records 已更新成 第2种方式



** 日志文件编码

** 日期的

** 移动对话框是否可以实现

** 保存上传日志文件
** 处理字段数据类型改变的后果， 比如 原来是名称（字符串） 变成 序号（数字）


1. 上传的 Excel 第一行 必须为 字段名

2. 尽量避免字段数据类型改变， 比如 原来是名称（字符串） 变成 序号（数字），因为这样的改变会使筛选条件可能失效。可以采取新增字段的方式。



这个Excel读取哪一行可以我们自己控制



OK，这个确实挺重要的，当时没考虑到，你把问题汇总，我后期一并加上
** 文件类型修改成枚举
   SCHEDULED: <2016-04-24 周日>
   CLOCK: [2016-04-24 周日 09:57]--[2016-04-24 周日 10:04] =>  0:07

最好是能定义成 值+描述的形式

两者都可以用获取得到

** 合并返回的表格数据
   CLOCK: [2016-04-24 周日 14:47]--[2016-04-24 周日 14:54] =>  0:07
   CLOCK: [2016-04-24 周日 08:59]--[2016-04-24 周日 09:17] =>  0:18
   CLOCK: [2016-04-23 周六 21:00]--[2016-04-23 周六 21:32] =>  0:32
** 实现通过传递刷选编号查询数据
   SCHEDULED: <2016-04-15 周五>
   CLOCK: [2016-04-23 周六 08:51]--[2016-04-23 周六 09:13] =>  0:22
   CLOCK: [2016-04-22 周五 21:14]--[2016-04-22 周五 21:52] =>  0:38
   CLOCK: [2016-04-19 周二 20:01]--[2016-04-19 周二 20:28] =>  0:27
   CLOCK: [2016-04-19 周二 19:45]--[2016-04-19 周二 20:00] =>  0:15
   CLOCK: [2016-04-18 周一 20:04]--[2016-04-18 周一 20:05] =>  0:01
   CLOCK: [2016-04-17 周日 20:02]--[2016-04-17 周日 20:49] =>  0:47
   CLOCK: [2016-04-15 周五 21:30]--[2016-04-15 周五 22:02] =>  0:32

【应该是去掉 data_id 】 相关的内容




【把所有 item 相同的都拼接在一起】






select recorddata0_.item_id as item_id1_0_, recorddata0_.data_id as data_id2_0_, recorddata0_.content as content3_0_ from t_data recorddata0_ where 
recorddata0_.item_id=1 and cast(content as decimal)>cast('1' as decimal) or 
recorddata0_.item_id=1 and cast(content as decimal)<cast('100' as decimal) or 
recorddata0_.item_id=7 and cast(content as date)>cast('2016-04-19' as date) 


【用这种算法来写，没错】
select recorddata0_.item_id as item_id1_0_, recorddata0_.data_id as data_id2_0_, recorddata0_.content as content3_0_ from t_data recorddata0_ where (recorddata0_.item_id<>1 or cast(content as decimal)>cast('1' as decimal)) and (recorddata0_.item_id<>1 or cast(content as decimal)<cast('100' as decimal)) and (recorddata0_.item_id<>7 or cast(content as date)>cast('2016-04-19' as date))

---------

like 




selet from t_data where (item_id=1 and content>1) or (item_id=1 and content<100)

要通过 HSQL 的字段类型来转变





select * from t_data where (item_id=1 and CAST(content AS FLOAT)>CAST('1' AS FLOAT)) or (item_id=1 and CAST(content AS FLOAT)<CAST('100' AS FLOAT));

select * from t_data where (item_id=1 and CAST(content AS FLOAT)>CAST('1' AS FLOAT));


select * from t_data where CAST(content AS int)>CAST('1' AS int);


select * from t_data where CAST(content AS int)=1;



mysql 中的值必须这样

DECIMAL

select * from t_data where (item_id=1 and CAST(content AS DECIMAL)>CAST('1' AS DECIMAL));

select * from t_data where (item_id=1 and CAST(content AS DECIMAL)>CAST('1' AS DECIMAL)) or (item_id=1 and CAST(content AS DECIMAL)<CAST('100' AS DECIMAL));



---------
herbnate 中 case 必须是 int ， float 这些基础数据类型

以前都是连接的ORACLE，MYSQL数据库，写程序一直也没出现过什么问题，就在近期用SQL SERVER出了点问题。

用hibernate操作sqlserver数据库，数据库表中有个日期字段是字符型，当查询一定时间范围内的数据时需要转换日期，这里需要注意了hibernate CAST函数支持转换类型在SQL SERVER中不一定行。
如：and cast(a.enterdate as date) >= cast('2009-01-01' as date) 


---------

String formatbgString = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(begintime);
String formatendString = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(begintime);

"and t.begintime > to_date('" + formatbgString + "', 'yyyy-MM-dd HH24:mi:ss') and t.endtime < to_date('" + formatendString + "', 'yyyy-MM-dd HH24:mi:ss')" 
** 用户刷选时，能够根据item项目进行调整
** 用户登录的界面
** excel解析

1. 需要考虑字段类型，并解析

** CRUD 查询数据
   CLOCK: [2016-04-13 周三 20:45]--[2016-04-13 周三 21:08] =>  0:23
   CLOCK: [2016-04-13 周三 19:42]--[2016-04-13 周三 20:28] =>  0:46
   CLOCK: [2016-04-13 周三 18:57]--[2016-04-13 周三 19:28] =>  0:31

angular Request Method:DELETE Status Code:415 Unsupported Media Type

改成post形式
		  <th>操作</th>
** excel 解析
1. 处理不同类型的解析


** 解析excel，以及整合项目
   SCHEDULED: <2016-04-10 周日>
   CLOCK: [2016-04-10 周日 22:03]--[2016-04-10 周日 22:34] =>  0:31


Description	Resource	Path	Location	Type
Unbound classpath container: 'JRE System Library [JavaSE-1.7]' in project 'DataManager'	DataManager		Build path	Build Path Problem

sted exception is java.lang.UnsupportedClassVersionError: com/soho/service/ItemService : Unsupported major.minor version 51.0

** 实现输入文件

http://v3.bootcss.com/css/#forms

表单
基本实例
** 插入和删除数据的批量更新
** 字段的排序功能
** 修改 MyEclipse 的注释风格
** 处理数据记录模型中的 type 字段
   SCHEDULED: <2016-03-16 周三>
** 字段名唯一问题
   CLOCK: [2016-03-19 周六 10:40]--[2016-03-19 周六 11:17] =>  0:37
1. 设置数据库字段唯一？
2. 设定 数据记录 唯一

** 整理使用手册
1. 截图等

** 优化界面
   CLOCK: [2016-03-17 周四 20:14]--[2016-03-17 周四 20:53] =>  0:39
   CLOCK: [2016-03-16 周三 21:38]--[2016-03-16 周三 22:41] =>  1:03
1. 发布 ExtJS release 版本
2. 改成修改那些改成中文版的提示



ycompressor


java -jar "D:\Program Files (x86)\SenchaSDKTools-2.0.0-beta3\compat\jsbuilder\ycompressor\ycompressor.jar" --type js --charset UTF-8 all-classes.js -o app-all.js

* communication

** web v2 

http://119.29.102.203:22080/DataManager


1. 用户登录信息：
   用户名: admin  密码: 123456
   用户名: user  密码: 123456
   用户名: 1  密码: 1
2. 注意上传的Excel文档需要设定日期所对应的单元格格式为“日期”
3. 每次上传的 excel 文档中满足字段名、验证条件的数据都会插入到数据库中
4. 注意字段管理中，如果字段类型不是“系统项”等需要验证的，请保持验证内容为空
5. “系统项”类型已增加，但上次交流中提到的序号类型，如果仅仅用于排序的话，觉得没有必要。因为下一步可能会实现按照某个字段的排序

*** 部署
   CLOCK: [2016-04-17 周日 17:40]--[2016-04-17 周日 18:11] =>  0:31

1. 更新MySQL库 (见文件末尾)
2. 插入数据
3. 访问 index.html

嘉明，现在完成的代码，我已经上传到服务器了。部署方式及现在的进度大致如下：


*** 还需完成的工作
1. 根据不同类型的 item 筛选条件来筛选数据
2. 解析 excel 文件，根据 item 以及 别名 识别并插入数据库中
3. 上传 excel 文件到服务器   

*** 总结
这次使用了新的库，不太熟练，遇到问题需要不断地测试，熟悉新的框架，难度增大了
同时，在已经有代码量，再增加大量代码，难度也增加了
因此，从而造成进度的延误了。


* learn
  CLOCK: [2016-04-15 周五 15:20]--[2016-04-15 周五 15:46] =>  0:26
** DONE linux 服务器中创建文件路径失败
   - State "DONE"       from ""           [2016-04-24 周日 21:07]
   CLOCK: [2016-04-24 周日 20:24]--[2016-04-24 周日 21:07] =>  0:43



PathUtil 中的问题


		if ("\\".equals(File.separator)) {
			if (s.startsWith("/") || s.startsWith("\\")) {
				s = s.substring(1);
				trim(s);
			}
		}

** jxl 在 linux 下读取失败
   SCHEDULED: <2016-04-24 周日>
1.修改JXL源代码中WriteAccessRecord文件代码，重新设置变量data的长度，例如：data = new byte[astring.getBytes().length];
2.只要在代码中强制设置变量WorkbookSettings.writeAccess的值即可，例如：
Workbook wb = Workbook.getWorkbook(new File("XXXXX"));
WorkbookSettings settings = new WorkbookSettings ();
settings.setWriteAccess(null); 


** DONE SpringWeb 获取当前服务器路径
   - State "DONE"       from ""           [2016-04-24 周日 17:48]
   CLOCK: [2016-04-24 周日 17:19]--[2016-04-24 周日 17:48] =>  0:29
   CLOCK: [2016-04-24 周日 14:55]--[2016-04-24 周日 14:57] =>  0:02

** Java.io.FileNotFoundException: class path resource [soho-dispatcher-servlet.xml] cannot be opened because it does not exist

1. mvn clean package

2. clean - rebuild


** DONE 上传文件到服务器
   - State "DONE"       from ""           [2016-04-24 周日 16:47]
   CLOCK: [2016-04-24 周日 16:18]--[2016-04-24 周日 16:47] =>  0:29
   CLOCK: [2016-04-24 周日 15:42]--[2016-04-24 周日 16:10] =>  0:28
   CLOCK: [2016-04-24 周日 14:57]--[2016-04-24 周日 15:30] =>  0:33


** SpringWeb 测试 Controller
** hsql 中多表查询形式
   SCHEDULED: <2016-04-19 周二>
   CLOCK: [2016-04-19 周二 21:11]--[2016-04-19 周二 21:15] =>  0:04
   CLOCK: [2016-04-19 周二 21:10]--[2016-04-19 周二 21:11] =>  0:01

* need

1. 上传excel能否一次选择多个文件？
   一次一个就行

2. 查询条件中 "广东,广西" ，认为采取与“字段”下拉框的处理方式比较好：
   比如： 1. 字段 2. 比较条件(大于、匹配、小于) 3. 值
   改成并且的关系

3. 能够对数据表进行增删改查的功能。 这一项需要有web界面吗？
   不需要，为以后预留


* code & tech
** datamanage php code


执行 sql 传入参数格式：

        $values_arr = array();

        $values_arr[0] = ["item test", 1];


---------

        $arrlength = count($rec);

        for ($x = 0; $x < $arrlength; $x++) {
            $t = $rec[$x];
            $len = count($t);

            for ($i = 0; $i < $len; $i++) {
                echo $t[$i] . ", ";
            }

            echo "<br>";
        }

---------

select max(item_id) as maxid from t_item


---------

** mysql

alter database datamanager character set utf8;

alter database datamanager character set utf8 COLLATE utf8_chinese_ci;;


create database datamanager character set utf8 COLLATE utf8_chinese_ci;

---------
不能执行这条语句： $this->conn = new mysqli(self::host, self::user, self::password, self::db, self::port);

【解决办法】

设置 php.ini 中的  mysqli.dll 这一项

extension=php_mysqli.dll




(+ 760 710)

** extjs

sencha create jsb -a http://localhost:8080/DataManager/temp.jsp -p app.jsb3

sencha build -p app.jsb3 -d .


java -jar "d:/Program Files (x86)/SenchaSDKTools-2.0.0-beta3/compat/jsbuilder/ycompressor/ycompressor.jar" --type js --charset utf-8 -v all-classes.js > app-all.js 


** maven

maven 编码GBK的不可映射字符


* sql 

drop database datamanager;

create database datamanager character set utf8 COLLATE utf8_general_ci;

use datamanager


select * from t_item;

delete from t_data;

select * from t_data;


insert into t_item(name, type, order_num) values('字段1', 1, 1);
insert into t_item(name, type, order_num) values('字段2', 1, 1);
insert into t_item(name, type, order_num) values('备注', 1, 1);



insert into t_data(data_id, item_id, content) values(1, 1, '内容1');
insert into t_data(data_id, item_id, content) values(1, 2, '内容2');



insert into t_othername(item_id, name) values(1, '别名1');
insert into t_othername(item_id, name) values(1, '别名2');



insert into t_validate(item_id, validate_item) values(1, '验证1');
insert into t_validate(item_id, validate_item) values(1, '验证2');


---------

INSERT INTO `t_item` (`item_id`, `name`, `type`, `order_num`, `maxlength`) VALUES
(1, '编号', 0, 1, 1000),
(2, '名称', 0, 0, 100),
(3, '字段名', 0, 100, 100),
(5, '字段2', 1, 2, 10),
(6, '备注', 1, 90, 1000),
(7, '日期', 1, 90, 50);


INSERT INTO `t_othername` (`othername_id`, `item_id`, `name`) VALUES
(10, 1, '别名1'),
(11, 1, '别名1'),
(12, 1, '别名2'),

INSERT INTO `t_validate` (`validate_id`, `item_id`, `validate_item`) VALUES
(10, 1, '验证1'),
(11, 1, '验证1'),
(12, 1, '验证2');



INSERT INTO `t_user` (`username`, `password`) VALUES
('admin', '123456'),
('user', '123456'),
('1', '1');


INSERT INTO `t_pick` (`pick_id`, `pick_name`) VALUES
(1, '筛选1'),
(2, '筛选2');


INSERT INTO `t_pick_item` (`pick_item_id`, `pick_id`, `item_id`, `choice`, `pick_value`) VALUES
(1, 1, '1', 0, '1'),
(2, 1, '1', 2, '100');


INSERT INTO `t_data` (`data_id`, `item_id`, `content`) VALUES
(1, 1, '1'),
(1, 2, '1'),
(1, 3, '1'),
(2, 1, '2'),
(2, 2, '2'),
(2, 3, '2');


update t_item set type=1 where item_id=1;




INSERT INTO `t_data` (`data_id`, `item_id`, `content`) VALUES
(1, 7, '2016-04-10'),
(2, 7, '2016-04-20');


select * from t_pick_item;


update t_pick_item set pick_value=100 where pick_item_id=2;



INSERT INTO `t_pick_item` (`pick_id`, `item_id`, `choice`, `pick_value`) VALUES
(1, 7, 0, '2016-04-19');




delete from t_data;
